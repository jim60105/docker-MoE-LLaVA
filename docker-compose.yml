services:
  moe-llava:
    container_name: moe-llava
    image: ghcr.io/jim60105/moe-llava:latest
    user: "1001:0"
    build:
      context: .
      dockerfile: Dockerfile
      target: final
      args:
        - UID=1001
        - LOW_VRAM=1
      cache_from:
        - ghcr.io/jim60105/moe-llava:cache
      cache_to:
        - type=inline
    tmpfs:
      - /tmp
    volumes:
      - .:/dataset
      - cache:/.cache
    # Gradio is launched with `demo.launch(share=True)`, so this is not working.
    # Needs to listen on host 0.0.0.0 for Docker networking.
    # ports:
    #   - "7860:7860"
    entrypoint:
      - "dumb-init"
      - "--"
      - "deepspeed"
      - "--num_gpus=1"
      - "/app/serve/gradio_web_server.py"
      - "--model-path"
      - "LanguageBind/MoE-LLaVA-StableLM-1.6B-4e-384"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]
              count: all

volumes:
  cache:
